{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tool\n",
    "\n",
    "import scipy, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, fixed, IntSlider\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data import\n",
    "\"\"\"\n",
    "asset_index = pd.read_csv(\"data/aidx_eod_prices.csv\")\n",
    "\n",
    "# data sorting/longer than 800 days\n",
    "grouped_asset = asset_index.groupby(\"S_IRDCODE\")\n",
    "asset_dfs = {ird_code: group for ird_code, group in grouped_asset if len(group) >= 800}\n",
    "for ird_code, grouped_df in asset_dfs.items():\n",
    "    grouped_df['TRADE_DT'] = pd.to_datetime(grouped_df['TRADE_DT'], format='%Y%m%d')\n",
    "    grouped_df.sort_values(by='TRADE_DT', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Parameters\n",
    "\"\"\"\n",
    "\n",
    "BACKTEST_DAY = 30 # lookback period (not used)\n",
    "TARGET_RETURN = 0.0 # target return\n",
    "RISK_FREE_RATE = 0.02 # risk-free rate\n",
    "\n",
    "NUM_ITERATION = 10 # test amounts\n",
    "NUM_LIMIT = (5, 10) # assets amount limitation range\n",
    "CORR_LIMIT = 0.5 # assets' correlation limiation\n",
    "\n",
    "REBALANCE_DAYS = [210] # rebalancing days test\n",
    "MODEL_TYPES = ['RB-SLSQP', 'RB-GA'] # test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Model rebalancing function\n",
    "\"\"\"\n",
    "\n",
    "def rebalance(asset_index, rebalance_day, weight_constraints, model_type):\n",
    "    predicts = []\n",
    "    actuals = []\n",
    "    realities = []\n",
    "    \n",
    "    for i in range(rebalance_day, len(asset_index), rebalance_day):\n",
    "        \n",
    "        if i+rebalance_day >= len(asset_index):\n",
    "            break\n",
    "        \n",
    "        historical_data = asset_index[i-rebalance_day:i]\n",
    "        future_data = asset_index[i:i+rebalance_day]\n",
    "        \n",
    "        predict, actual, _ = tool.evaluate(historical_data, future_data, weight_constraints, model_type, TARGET_RETURN, RISK_FREE_RATE)\n",
    "        predicts.append(predict)\n",
    "        actuals.append(actual)\n",
    "        \n",
    "        # equally weighed\n",
    "        reality = tool.check([1 / len(asset_index.columns) for _ in range(len(asset_index.columns))], future_data, RISK_FREE_RATE)\n",
    "        realities.append(reality)\n",
    "    \n",
    "    return predicts, actuals, realities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Asset sampling\n",
    "\"\"\"\n",
    "\n",
    "def sample(num_limit, asset_dfs, corr_limit):\n",
    "    index_list = random.sample(list(asset_dfs.keys()), num_limit)\n",
    "    \n",
    "    def is_non_related(index_list):\n",
    "        for i in range(0, len(index_list)):\n",
    "            for j in range(i+1, len(index_list)):\n",
    "                i_df = asset_dfs[index_list[i]]\n",
    "                j_df = asset_dfs[index_list[j]]\n",
    "                min_length = min(len(i_df['PCHG']), len(j_df['PCHG']))\n",
    "                corr, _ = scipy.stats.spearmanr(i_df['PCHG'].iloc[:min_length], j_df['PCHG'].iloc[:min_length])\n",
    "                if corr > corr_limit:\n",
    "                    return False\n",
    "        return True\n",
    "    \n",
    "    while is_non_related(index_list) == False:\n",
    "        index_list = random.sample(list(asset_dfs.keys()), num_limit)\n",
    "    \n",
    "    return index_list\n",
    "\n",
    "# sample(20, asset_dfs, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Different Models with the same assets (randomly generated) and different rebalancing days\n",
    "\"\"\"\n",
    "\n",
    "def asset_rebalance(asset, num_limit, model_types, rebalancing_days, asset_dfs, corr_limit):\n",
    "    \n",
    "    asset_index = asset.copy()\n",
    "    \n",
    "    # randomly select assets\n",
    "    actual_num_limit = np.random.randint(*num_limit)\n",
    "    index_list = sample(actual_num_limit, asset_dfs, corr_limit)\n",
    "    asset_index['TRADE_DT'] = pd.to_datetime(asset_index['TRADE_DT'], format='%Y%m%d')\n",
    "    asset_index.sort_values(by='TRADE_DT', inplace=True)\n",
    "    asset_index.set_index('TRADE_DT', inplace=True)\n",
    "    asset_index = asset_index.pivot(columns='S_IRDCODE', values='CLOSE').ffill()[index_list].dropna()\n",
    "    \n",
    "    # weight constraints\n",
    "    n = len(index_list)\n",
    "    index_min_weight = [0 for _ in range(n)]\n",
    "    index_max_weight = [1 for _ in range(n)]\n",
    "    weight_constraints = list(zip(index_min_weight, index_max_weight))\n",
    "    \n",
    "    # start iteration\n",
    "    results = {}\n",
    "    for model_type in model_types:\n",
    "        for rebalance_day in rebalancing_days:\n",
    "            _, actuals, realities = rebalance(asset_index, rebalance_day, weight_constraints, model_type)\n",
    "            results[(model_type, rebalance_day)] = list(zip(*actuals))\n",
    "            results[('EW', rebalance_day)] = list(zip(*realities))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# results = asset_rebalance(asset_index, 5, MODEL_TYPES, [300, 600], asset_dfs, CORR_LIMIT)\n",
    "# results = dict(sorted(results.items(), key=lambda item: item[0][1]))\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate the average for one assets combination with each (model, rebalance_day)\n",
    "\"\"\"\n",
    "\n",
    "def calculate_averages(data, exclude_model='EW'):\n",
    "    grouped_data = defaultdict(dict)\n",
    "\n",
    "    # Group data by the second key of the tuple\n",
    "    for (model, period), values in data.items():\n",
    "        grouped_data[period][model] = values\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # Perform division and calculate averages\n",
    "    for period, models in grouped_data.items():\n",
    "        ew_values = models.get(exclude_model)\n",
    "        if ew_values is None:\n",
    "            continue  # Skip if 'EW' data is not present\n",
    "\n",
    "        for model, values in models.items():\n",
    "            if model != exclude_model:\n",
    "                modified_values = []\n",
    "                for index, (value, ew_value) in enumerate(zip(values, ew_values)):\n",
    "                    if index == 0:  # For the first set, use subtraction\n",
    "                        result = [v - ew for v, ew in zip(value, ew_value)]\n",
    "                    else:  # For the other sets, use division\n",
    "                        result = [v / ew if ew != 0 else 0 for v, ew in zip(value, ew_value)]\n",
    "                    modified_values.append(result)\n",
    "                    \n",
    "                averages = [sum(value) / len(value) for value in modified_values]\n",
    "                results[(model, period)] = averages\n",
    "\n",
    "    return results\n",
    "\n",
    "# t = calculate_averages(results)\n",
    "# print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Tool\\Python3\\lib\\site-packages\\arch\\univariate\\base.py:766: ConvergenceWarning: The optimizer returned code 4. The message is:\n",
      "Inequality constraints incompatible\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Tool\\Python3\\lib\\site-packages\\arch\\univariate\\base.py:766: ConvergenceWarning: The optimizer returned code 4. The message is:\n",
      "Inequality constraints incompatible\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{('RB-SLSQP', 210): [0.032818699783103346, 0.9551859659986566, 1.0531336535168223], ('RB-GA', 210): [0.03281990792415034, 0.9551843865627566, 1.0531248011903838]}, {('RB-SLSQP', 210): [-0.0009060788577487759, 1.007173220591763, 0.9743391877706467], ('RB-GA', 210): [-0.0009060322525207283, 1.0071731320294959, 0.9743511808317816]}, {('RB-SLSQP', 210): [-0.003104558434930743, 0.9503157892948582, 0.9918186879525499], ('RB-GA', 210): [-0.0031067431525756244, 0.9502981401846989, 0.9918357285566403]}, {('RB-SLSQP', 210): [-0.0020619359518528244, 1.006508959732311, 0.9207451138428747], ('RB-GA', 210): [-0.002062450919137912, 1.0065031191800136, 0.920756475823794]}, {('RB-SLSQP', 210): [0.009851203346994424, 1.0092176401798598, 0.9320606478838862], ('RB-GA', 210): [0.00985148282652338, 1.0092113403944758, 0.9320598982631715]}, {('RB-SLSQP', 210): [0.0003866839010531253, 1.0672081529710105, 0.7342266305967649], ('RB-GA', 210): [0.00038529668657036646, 1.0671988959966066, 0.7342082194733393]}, {('RB-SLSQP', 210): [0.00923274556029879, 0.8575275695023447, 1.0928982018054119], ('RB-GA', 210): [0.005955039276013598, 0.8707654076002458, 1.0901985309583213]}, {('RB-SLSQP', 210): [-0.0008872393378524782, 0.9933475714318868, 1.063271004869644], ('RB-GA', 210): [-0.0008869926349086268, 0.9933507102271497, 1.0632497394512945]}, {('RB-SLSQP', 210): [0.0018235702988962225, 1.0120197695728925, 0.8272366574374239], ('RB-GA', 210): [0.0018240375702724752, 1.012018825115148, 0.8272227300533622]}, {('RB-SLSQP', 210): [-0.007805648969780294, 0.9351693367898137, 0.930336108313659], ('RB-GA', 210): [-0.007803051301102722, 0.9351592233912939, 0.9303436763368994]}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Iteration start\n",
    "\"\"\"\n",
    "\n",
    "final_results = []\n",
    "for i in range(0, NUM_ITERATION):\n",
    "    results = asset_rebalance(asset_index, NUM_LIMIT, MODEL_TYPES, REBALANCE_DAYS, asset_dfs, CORR_LIMIT)\n",
    "    results = dict(sorted(results.items(), key=lambda item: item[0][1]))\n",
    "    results = calculate_averages(results)\n",
    "    final_results.append(results)\n",
    "\n",
    "print(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('RB-SLSQP', 210): [0.032818699783103346, 0.9551859659986566, 1.0531336535168223], ('RB-GA', 210): [0.03281990792415034, 0.9551843865627566, 1.0531248011903838]}\n",
      "{('RB-SLSQP', 210): [-0.0009060788577487759, 1.007173220591763, 0.9743391877706467], ('RB-GA', 210): [-0.0009060322525207283, 1.0071731320294959, 0.9743511808317816]}\n",
      "{('RB-SLSQP', 210): [-0.003104558434930743, 0.9503157892948582, 0.9918186879525499], ('RB-GA', 210): [-0.0031067431525756244, 0.9502981401846989, 0.9918357285566403]}\n",
      "{('RB-SLSQP', 210): [-0.0020619359518528244, 1.006508959732311, 0.9207451138428747], ('RB-GA', 210): [-0.002062450919137912, 1.0065031191800136, 0.920756475823794]}\n",
      "{('RB-SLSQP', 210): [0.009851203346994424, 1.0092176401798598, 0.9320606478838862], ('RB-GA', 210): [0.00985148282652338, 1.0092113403944758, 0.9320598982631715]}\n",
      "{('RB-SLSQP', 210): [0.0003866839010531253, 1.0672081529710105, 0.7342266305967649], ('RB-GA', 210): [0.00038529668657036646, 1.0671988959966066, 0.7342082194733393]}\n",
      "{('RB-SLSQP', 210): [0.00923274556029879, 0.8575275695023447, 1.0928982018054119], ('RB-GA', 210): [0.005955039276013598, 0.8707654076002458, 1.0901985309583213]}\n",
      "{('RB-SLSQP', 210): [-0.0008872393378524782, 0.9933475714318868, 1.063271004869644], ('RB-GA', 210): [-0.0008869926349086268, 0.9933507102271497, 1.0632497394512945]}\n",
      "{('RB-SLSQP', 210): [0.0018235702988962225, 1.0120197695728925, 0.8272366574374239], ('RB-GA', 210): [0.0018240375702724752, 1.012018825115148, 0.8272227300533622]}\n",
      "{('RB-SLSQP', 210): [-0.007805648969780294, 0.9351693367898137, 0.930336108313659], ('RB-GA', 210): [-0.007803051301102722, 0.9351592233912939, 0.9303436763368994]}\n",
      "{('RB-SLSQP', 210): [(0.032818699783103346, -0.0009060788577487759, -0.003104558434930743, -0.0020619359518528244, 0.009851203346994424, 0.0003866839010531253, 0.00923274556029879, -0.0008872393378524782, 0.0018235702988962225, -0.007805648969780294), (0.9551859659986566, 1.007173220591763, 0.9503157892948582, 1.006508959732311, 1.0092176401798598, 1.0672081529710105, 0.8575275695023447, 0.9933475714318868, 1.0120197695728925, 0.9351693367898137), (1.0531336535168223, 0.9743391877706467, 0.9918186879525499, 0.9207451138428747, 0.9320606478838862, 0.7342266305967649, 1.0928982018054119, 1.063271004869644, 0.8272366574374239, 0.930336108313659)], ('RB-GA', 210): [(0.03281990792415034, -0.0009060322525207283, -0.0031067431525756244, -0.002062450919137912, 0.00985148282652338, 0.00038529668657036646, 0.005955039276013598, -0.0008869926349086268, 0.0018240375702724752, -0.007803051301102722), (0.9551843865627566, 1.0071731320294959, 0.9502981401846989, 1.0065031191800136, 1.0092113403944758, 1.0671988959966066, 0.8707654076002458, 0.9933507102271497, 1.012018825115148, 0.9351592233912939), (1.0531248011903838, 0.9743511808317816, 0.9918357285566403, 0.920756475823794, 0.9320598982631715, 0.7342082194733393, 1.0901985309583213, 1.0632497394512945, 0.8272227300533622, 0.9303436763368994)]}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Output\n",
    "\"\"\"\n",
    "\n",
    "def aggregate_results(dicts):\n",
    "    aggregated_results = {}\n",
    "\n",
    "    # Initialize aggregated_results with empty lists for each key\n",
    "    for key in dicts[0].keys():\n",
    "        aggregated_results[key] = []\n",
    "\n",
    "    # Iterate over each dictionary\n",
    "    for d in dicts:\n",
    "        print(d)\n",
    "        for key, values in d.items():\n",
    "            # Assuming all dictionaries have the same structure\n",
    "            for i, value in enumerate(values):\n",
    "                if len(aggregated_results[key]) <= i:\n",
    "                    aggregated_results[key].append([])\n",
    "                aggregated_results[key][i].append(value)\n",
    "\n",
    "    # Convert lists of values to tuples\n",
    "    for key in aggregated_results:\n",
    "        aggregated_results[key] = [tuple(lst) for lst in aggregated_results[key]]\n",
    "\n",
    "    return aggregated_results\n",
    "\n",
    "aggregated_results = aggregate_results(final_results)\n",
    "print(aggregated_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16af97d71ba4a198c127c7fbfbebf52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Checkbox(value=False, description='normalise'), IntSlider(value=0, description='i', max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.asset_display(data, normalise=True, i=0)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Visualisation\n",
    "\"\"\"\n",
    "\n",
    "def asset_display(data, normalise=True, i=0):\n",
    "    line_styles = ['-', '--', ':']\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(data)))\n",
    "\n",
    "    def normalize_data(lst):\n",
    "        return (lst - np.mean(lst)) / np.std(lst)\n",
    "\n",
    "    line_style = line_styles[i]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    lines = []\n",
    "\n",
    "    for (key, lists), color in zip(data.items(), colors):\n",
    "        if i < len(lists):\n",
    "            lst = lists[i]\n",
    "            l = normalize_data(lst) if normalise else lst\n",
    "            l = np.array(lst)\n",
    "            # l = l[~np.isnan(l)]\n",
    "            line, = ax.plot(l, line_style, color=color, label=f'{key}')\n",
    "            lines.append(line)\n",
    "    \n",
    "    if i == 0:\n",
    "        ax.axhline(y=0, color='red', linestyle=':')\n",
    "    elif i == 1:\n",
    "        ax.axhline(y=1, color='red', linestyle=':')\n",
    "        \n",
    "    plt.subplots_adjust(right=0.7)\n",
    "    leg = ax.legend(fancybox=True, shadow=True, loc='center left', bbox_to_anchor=(1, 0.5), ncol=2)\n",
    "    \n",
    "    lined = {}\n",
    "    for legline, origline in zip(leg.get_lines(), lines):\n",
    "        legline.set_picker(5)\n",
    "        lined[legline] = origline\n",
    "        \n",
    "    for legline, line in zip(leg.get_lines(), lines):\n",
    "        legline.set_alpha(0.2)\n",
    "        line.set_visible(False)\n",
    "\n",
    "    avg_text_objects = {}\n",
    "    \n",
    "    def on_pick(event):\n",
    "        legline = event.artist\n",
    "        origline = lined[legline]\n",
    "        visible = not origline.get_visible()\n",
    "        origline.set_visible(visible)\n",
    "        \n",
    "        if visible:\n",
    "            if origline not in avg_text_objects:\n",
    "                display_position = (0.05, 0.95 - 0.05 * len(avg_text_objects))\n",
    "                avg_value = np.nanmean(origline.get_ydata())\n",
    "                avg_text_objects[origline] = ax.text(display_position[0], display_position[1], \n",
    "                                                     f'Avg {legline.get_label()}: {avg_value:.4f}', \n",
    "                                                     transform=ax.transAxes, color=origline.get_color(),\n",
    "                                                     fontsize=9, verticalalignment='top')\n",
    "            else:\n",
    "                avg_text_objects[origline].set_visible(True)\n",
    "        else:\n",
    "            if origline in avg_text_objects:\n",
    "                avg_text_objects[origline].set_visible(False)\n",
    "                del avg_text_objects[origline]\n",
    "\n",
    "        legline.set_alpha(1.0 if visible else 0.2)\n",
    "        fig.canvas.draw()\n",
    "\n",
    "    fig.canvas.mpl_connect('pick_event', on_pick)\n",
    "\n",
    "    titles = {0 : 'Return', 1 : 'Volatility', 2 : 'Sharpe Ratio'}\n",
    "    ax.set_title(titles.get(i, 'Q2 Line Plots'))\n",
    "    ax.set_xlabel('Test Index')\n",
    "    ax.set_ylabel('Value')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "interact(asset_display,\n",
    "         data=fixed(aggregated_results),\n",
    "         normalise=False,\n",
    "         i=IntSlider(min=0, max=2, step=1, value=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

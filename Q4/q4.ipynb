{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tool\n",
    "\n",
    "import scipy, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, fixed, IntSlider\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data import\n",
    "\"\"\"\n",
    "asset_index = pd.read_csv(\"data/aidx_eod_prices.csv\")\n",
    "\n",
    "# data sorting/longer than 800 days\n",
    "grouped_asset = asset_index.groupby(\"S_IRDCODE\")\n",
    "asset_dfs = {ird_code: group for ird_code, group in grouped_asset if len(group) >= 800}\n",
    "for ird_code, grouped_df in asset_dfs.items():\n",
    "    grouped_df['TRADE_DT'] = pd.to_datetime(grouped_df['TRADE_DT'], format='%Y%m%d')\n",
    "    grouped_df.sort_values(by='TRADE_DT', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Parameters\n",
    "\"\"\"\n",
    "\n",
    "BACKTEST_DAY = 30 # lookback period (not used)\n",
    "TARGET_RETURN = 0.0 # target return\n",
    "RISK_FREE_RATE = 0.02 # risk-free rate\n",
    "\n",
    "NUM_ITERATION = 10 # test amounts\n",
    "NUM_LIMIT = (5, 10) # assets amount limitation range\n",
    "CORR_LIMIT = 0.5 # assets' correlation limiation\n",
    "\n",
    "REBALANCE_DAYS = [210] # rebalancing days test\n",
    "MODEL_TYPES = ['RB-SLSQP', 'RB-GA'] # test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Model rebalancing function\n",
    "\"\"\"\n",
    "\n",
    "def rebalance(asset_index, rebalance_day, weight_constraints, model_type):\n",
    "    predicts = []\n",
    "    actuals = []\n",
    "    realities = []\n",
    "    \n",
    "    for i in range(rebalance_day, len(asset_index), rebalance_day):\n",
    "        \n",
    "        if i+rebalance_day >= len(asset_index):\n",
    "            break\n",
    "        \n",
    "        historical_data = asset_index[i-rebalance_day:i]\n",
    "        future_data = asset_index[i:i+rebalance_day]\n",
    "        \n",
    "        predict, actual = tool.evaluate(historical_data, future_data, weight_constraints, model_type, TARGET_RETURN, RISK_FREE_RATE)\n",
    "        predicts.append(predict)\n",
    "        actuals.append(actual)\n",
    "        \n",
    "        # equally weighed\n",
    "        reality = tool.check([1 / len(asset_index.columns) for _ in range(len(asset_index.columns))], future_data, RISK_FREE_RATE)\n",
    "        realities.append(reality)\n",
    "    \n",
    "    return predicts, actuals, realities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Asset sampling\n",
    "\"\"\"\n",
    "\n",
    "def sample(num_limit, asset_dfs, corr_limit):\n",
    "    index_list = random.sample(list(asset_dfs.keys()), num_limit)\n",
    "    \n",
    "    def is_non_related(index_list):\n",
    "        for i in range(0, len(index_list)):\n",
    "            for j in range(i+1, len(index_list)):\n",
    "                i_df = asset_dfs[index_list[i]]\n",
    "                j_df = asset_dfs[index_list[j]]\n",
    "                min_length = min(len(i_df['PCHG']), len(j_df['PCHG']))\n",
    "                corr, _ = scipy.stats.spearmanr(i_df['PCHG'].iloc[:min_length], j_df['PCHG'].iloc[:min_length])\n",
    "                if corr > corr_limit:\n",
    "                    return False\n",
    "        return True\n",
    "    \n",
    "    while is_non_related(index_list) == False:\n",
    "        index_list = random.sample(list(asset_dfs.keys()), num_limit)\n",
    "    \n",
    "    return index_list\n",
    "\n",
    "# sample(20, asset_dfs, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Different Models with the same assets (randomly generated) and different rebalancing days\n",
    "\"\"\"\n",
    "\n",
    "def asset_rebalance(asset, num_limit, model_types, rebalancing_days, asset_dfs, corr_limit):\n",
    "    \n",
    "    asset_index = asset.copy()\n",
    "    \n",
    "    # randomly select assets\n",
    "    actual_num_limit = np.random.randint(*num_limit)\n",
    "    index_list = sample(actual_num_limit, asset_dfs, corr_limit)\n",
    "    asset_index['TRADE_DT'] = pd.to_datetime(asset_index['TRADE_DT'], format='%Y%m%d')\n",
    "    asset_index.sort_values(by='TRADE_DT', inplace=True)\n",
    "    asset_index.set_index('TRADE_DT', inplace=True)\n",
    "    asset_index = asset_index.pivot(columns='S_IRDCODE', values='CLOSE').ffill()[index_list].dropna()\n",
    "    \n",
    "    # weight constraints\n",
    "    n = len(index_list)\n",
    "    index_min_weight = [0 for _ in range(n)]\n",
    "    index_max_weight = [1 for _ in range(n)]\n",
    "    weight_constraints = list(zip(index_min_weight, index_max_weight))\n",
    "    \n",
    "    # start iteration\n",
    "    results = {}\n",
    "    for model_type in model_types:\n",
    "        for rebalance_day in rebalancing_days:\n",
    "            _, actuals, realities = rebalance(asset_index, rebalance_day, weight_constraints, model_type)\n",
    "            results[(model_type, rebalance_day)] = list(zip(*actuals))\n",
    "            results[('EW', rebalance_day)] = list(zip(*realities))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# results = asset_rebalance(asset_index, 5, MODEL_TYPES, [300, 600], asset_dfs, CORR_LIMIT)\n",
    "# results = dict(sorted(results.items(), key=lambda item: item[0][1]))\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate the average for one assets combination with each (model, rebalance_day)\n",
    "\"\"\"\n",
    "\n",
    "def calculate_averages(data, exclude_model='EW'):\n",
    "    grouped_data = defaultdict(dict)\n",
    "\n",
    "    # Group data by the second key of the tuple\n",
    "    for (model, period), values in data.items():\n",
    "        grouped_data[period][model] = values\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # Perform division and calculate averages\n",
    "    for period, models in grouped_data.items():\n",
    "        ew_values = models.get(exclude_model)\n",
    "        if ew_values is None:\n",
    "            continue  # Skip if 'EW' data is not present\n",
    "\n",
    "        for model, values in models.items():\n",
    "            if model != exclude_model:\n",
    "                modified_values = []\n",
    "                for index, (value, ew_value) in enumerate(zip(values, ew_values)):\n",
    "                    if index == 0:  # For the first set, use subtraction\n",
    "                        result = [v - ew for v, ew in zip(value, ew_value)]\n",
    "                    else:  # For the other sets, use division\n",
    "                        result = [v / ew if ew != 0 else 0 for v, ew in zip(value, ew_value)]\n",
    "                    modified_values.append(result)\n",
    "                    \n",
    "                averages = [sum(value) / len(value) for value in modified_values]\n",
    "                results[(model, period)] = averages\n",
    "\n",
    "    return results\n",
    "\n",
    "# t = calculate_averages(results)\n",
    "# print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Iteration start\n",
    "\"\"\"\n",
    "\n",
    "final_results = []\n",
    "for i in range(0, NUM_ITERATION):\n",
    "    results = asset_rebalance(asset_index, NUM_LIMIT, MODEL_TYPES, REBALANCE_DAYS, asset_dfs, CORR_LIMIT)\n",
    "    results = dict(sorted(results.items(), key=lambda item: item[0][1]))\n",
    "    results = calculate_averages(results)\n",
    "    final_results.append(results)\n",
    "\n",
    "print(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Output\n",
    "\"\"\"\n",
    "\n",
    "def aggregate_results(dicts):\n",
    "    aggregated_results = {}\n",
    "\n",
    "    # Initialize aggregated_results with empty lists for each key\n",
    "    for key in dicts[0].keys():\n",
    "        aggregated_results[key] = []\n",
    "\n",
    "    # Iterate over each dictionary\n",
    "    for d in dicts:\n",
    "        print(d)\n",
    "        for key, values in d.items():\n",
    "            # Assuming all dictionaries have the same structure\n",
    "            for i, value in enumerate(values):\n",
    "                if len(aggregated_results[key]) <= i:\n",
    "                    aggregated_results[key].append([])\n",
    "                aggregated_results[key][i].append(value)\n",
    "\n",
    "    # Convert lists of values to tuples\n",
    "    for key in aggregated_results:\n",
    "        aggregated_results[key] = [tuple(lst) for lst in aggregated_results[key]]\n",
    "\n",
    "    return aggregated_results\n",
    "\n",
    "aggregated_results = aggregate_results(final_results)\n",
    "print(aggregated_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Visualisation\n",
    "\"\"\"\n",
    "\n",
    "def asset_display(data, normalise=True, i=0):\n",
    "    line_styles = ['-', '--', ':']\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(data)))\n",
    "\n",
    "    def normalize_data(lst):\n",
    "        return (lst - np.mean(lst)) / np.std(lst)\n",
    "\n",
    "    line_style = line_styles[i]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    lines = []\n",
    "\n",
    "    for (key, lists), color in zip(data.items(), colors):\n",
    "        if i < len(lists):\n",
    "            lst = lists[i]\n",
    "            l = normalize_data(lst) if normalise else lst\n",
    "            l = np.array(lst)\n",
    "            # l = l[~np.isnan(l)]\n",
    "            line, = ax.plot(l, line_style, color=color, label=f'{key}')\n",
    "            lines.append(line)\n",
    "    \n",
    "    if i == 0:\n",
    "        ax.axhline(y=0, color='red', linestyle=':')\n",
    "    elif i == 1:\n",
    "        ax.axhline(y=1, color='red', linestyle=':')\n",
    "        \n",
    "    plt.subplots_adjust(right=0.7)\n",
    "    leg = ax.legend(fancybox=True, shadow=True, loc='center left', bbox_to_anchor=(1, 0.5), ncol=2)\n",
    "    \n",
    "    lined = {}\n",
    "    for legline, origline in zip(leg.get_lines(), lines):\n",
    "        legline.set_picker(5)\n",
    "        lined[legline] = origline\n",
    "        \n",
    "    for legline, line in zip(leg.get_lines(), lines):\n",
    "        legline.set_alpha(0.2)\n",
    "        line.set_visible(False)\n",
    "\n",
    "    avg_text_objects = {}\n",
    "    \n",
    "    def on_pick(event):\n",
    "        legline = event.artist\n",
    "        origline = lined[legline]\n",
    "        visible = not origline.get_visible()\n",
    "        origline.set_visible(visible)\n",
    "        \n",
    "        if visible:\n",
    "            if origline not in avg_text_objects:\n",
    "                display_position = (0.05, 0.95 - 0.05 * len(avg_text_objects))\n",
    "                avg_value = np.nanmean(origline.get_ydata())\n",
    "                avg_text_objects[origline] = ax.text(display_position[0], display_position[1], \n",
    "                                                     f'Avg {legline.get_label()}: {avg_value:.4f}', \n",
    "                                                     transform=ax.transAxes, color=origline.get_color(),\n",
    "                                                     fontsize=9, verticalalignment='top')\n",
    "            else:\n",
    "                avg_text_objects[origline].set_visible(True)\n",
    "        else:\n",
    "            if origline in avg_text_objects:\n",
    "                avg_text_objects[origline].set_visible(False)\n",
    "                del avg_text_objects[origline]\n",
    "\n",
    "        legline.set_alpha(1.0 if visible else 0.2)\n",
    "        fig.canvas.draw()\n",
    "\n",
    "    fig.canvas.mpl_connect('pick_event', on_pick)\n",
    "\n",
    "    titles = {0 : 'Return', 1 : 'Volatility', 2 : 'Sharpe Ratio'}\n",
    "    ax.set_title(titles.get(i, 'Q2 Line Plots'))\n",
    "    ax.set_xlabel('Test Index')\n",
    "    ax.set_ylabel('Value')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "interact(asset_display,\n",
    "         data=fixed(aggregated_results),\n",
    "         normalise=False,\n",
    "         i=IntSlider(min=0, max=2, step=1, value=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
